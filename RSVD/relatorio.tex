\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}
\usepackage{subfigure}
\usepackage{pgfplots}
\usepackage{amsmath}
% \usepackage{hyperref}

\usepackage[brazil]{babel}   
\usepackage[utf8]{inputenc}  

% \long\def\/*#1*/{}
     
\sloppy

\title{Avaliação de parâmetros para o algoritmo SVD regularizado}

\author{Cassiano H. da Silva\inst{1}, Geovani S. Celebrim\inst{1} }

\address{Departamento de Ciência da Computação \\ Universidade Federal Rural do Rio de Janeiro
  (UFRRJ)\\
  26.020-740 -- Nova Iguaçu -- RJ -- Brasil
\email{\{honoriocassiano, geovanicelebrim\}@gmail.com}
}

\begin{document} 

\maketitle
     
\begin{resumo} 

Motivados a tornar a experiência do usuário mais rica e interessante, os Sistemas de Recomendação tem como principal objetivo oferecer ao usuário um ambiente personalizado. Buscando obter técnicas mais robustas para essa personalização, os Sistemas de Recomendação baseados em modelo procuram otimizar o cálculo e armazenamento que é feito nos sistemas baseados em memória. Isso é feito criando-se um modelo onde o cálculo da recomendação seja mais rápido e escalável. Este trabalho propõe uma análise do algoritmo SVD regularizado, que busca fatores latentes que reúnem características de usuários e itens para realizar as predições. Ao final, é apresentado quais parâmetros melhor se adequaram para o cenário onde foram realizados os testes.

% Sistemas de Recomendação ajudam a personalizar a experiência dos usuários, oferecendo a eles conteúdos específicos que tendem a ser de seu interesse. Existem várias técnicas para construção de um Sistema de Recomendação, cada uma com seus algoritmos, suas vantagens e desvantagens.
% Este trabalho explora um algoritmo utilizado em Sistemas de Recomendação com Filtragem Colaborativa, o KNN. O principal objetivo do trabalho é realizar uma análise entre técnicas de similaridade existentes na literatura e outras aqui propostas. Ao final, espera-se que seja possível dizer qual técnica é mais eficiente para este conjunto de dados.

\end{resumo}

\section{Definição}

Os Sistemas de Recomendação buscam, através de técnicas distintas, prover ao usuário uma experiência personalizada. Para isso, é realizado um estudo das características e relações entre itens e usuários para que um novo item possa ser recomendado a um usuário \cite{tail2006future}. Tais características nem sempre são explícitas -- apesar de sabermos de sua existência -- e não podem ser diretamente extraídas. Essas características são chamadas de variáveis latentes \cite{borsboom2003theoretical}.

% Segundo \cite{burke1999integrating}, existem quatro tipos de recomendação: 1 - Filtragem Colaborativa, 2 - Filtragem Baseada em Conteúdo, 3 - Baseados em Conhecimento e 4 - Híbridos. Neste trabalho será utilizada a técnica de Filtragem Colaborativa \textcolor{red}{com predição baseada em usuário}, introduzida por \cite{resnick1994grouplens}, que recomendam itens baseados na utilização desses pela comunidade de usuários.

As técnicas de recomendação por filtragem colaborativa baseadas em modelo ganharam grande apelo especialmente após o concurso da Netflix \cite{bennett2007netflix}, onde o algoritmo que fazia uso de fatores latentes \cite{koren2009matrix} foi o que apresentou os melhores resultados. Nestes algoritmos, um modelo de predição de recomendação é proposto com treinamento utilizando um conjunto de dados separado para treino. Existem, na literatura, diversos tipos de modelos que apresentam bons resultados como \textit{Support Vector Machines} (SVM) \cite{grvcar2006knn} e \textit{Singular Value Decomposition} (SVD) \cite{takacs2009scalable}. 

Este trabalho tem como principal objetivo explorar o modelo SVD, que é uma poderosa técnica de fatoração que busca encontrar um espaço de recursos de menor dimensão onde as novas características representam ``conceitos'' e o peso de cada conceito no contexto da coleção é computável \cite{shapira2011recommender}. Com isso, o SVD permite obter automaticamente esses ``conceitos'' e utilizá-los como base para uma análise latente-semântica \cite{shapira2011recommender}, uma técnica popular de classificação de texto em \textit{Information Retrieval}.

As predições através desse modelo podem ser obtidas por $\bar{R}_{ij} = P^TQ$. Onde as matrizes $P$ e $Q$ representa as características latentes dos usuários e itens, respectivamente. Durante o procedimento de treino, que almeja diminuir o erro e, assim, melhorar as predições, deve-se realizar a minimização do erro quadrático apresentado na equação \ref{minimosQuadrados}, que é equivalente ao problema dos mínimos quadrados \cite{helene2006metodos}. Nesta equação é calculado a diferença entre a nota real $R$ e a nota predita $\bar{R}$ do usuário $u$ para o item $i$. Fazendo o uso dos método do gradiente descendente, os valores para atualização de $P$ e $Q$ são mostrados nas equações \ref{p} e \ref{q}, respectivamente, onde $lrate$ é a taxa de aprendizagem, $e$ é o erro da predição e $\lambda$ é a taxa de regularização.

\begin{equation} \label{minimosQuadrados}
\min\nolimits\sum\limits_{\substack{\forall u \in U\\ \forall i \in I}} (R_{ui} - \bar{R}_{ui})^2
\end{equation}

\begin{equation} \label{p}
P_{iu} = P_{iu} + lrate * ( e * Q_{ui} - \lambda * P_{iu})
\end{equation}

\begin{equation} \label{q}
Q_{ui} = Q_{ui} + lrate * ( e * P_{iu} - \lambda * Q_{ui})
\end{equation}

% Os algoritmos de Filtragem Colaborativa podem ser divididos em dois grandes grupos de técnicas: baseados em memória e baseados em modelo. Os algoritmos baseados em memória, também conhecidos como Baseados em Vizinhança, possuem grande destaque pelo pioneirismo \cite{goldberg1992using}. Para estes sistemas, o interesse do usuário \textit{u} no item \textit{i} é calculado usando as avaliações dos seus usuários mais próximos. Para isso, é necessário armazenar as avaliações de cada usuário e obter os \textit{K} usuários mais próximos de \textit{u}. Calcular essa proximidade de forma eficiente é fundamental para que se obtenha bons resultados. Na sessão seguinte são apresentadas as técnicas de cálculo de similaridade que foram estudadas neste trabalho.

% Sistemas de Recomendação exploram características e relações entre os usuários e itens com a finalidade de entender como se dá essa relação, para que seja capaz de realizar uma recomendação de um novo item para um usuário \cite{tail2006future}. As informações sobre essas características e relações podem ser capturadas do usuário e do item de forma implícita ou explícita, cada uma com suas vantagens e desvantagens.

% Existem diferentes tipos de Sistemas de Recomendação e o que caracteriza essa diferença é a forma como é criada a relação da interação entre os usuários e os itens, bem como a forma que a recomendação é processada. Segundo \cite{burke1999integrating}, existem basicamente quatro tipos de recomendação: 1 - Filtragem Colaborativa, 2 - Filtragem Baseada em Conteúdo, 3 - Baseados em Conhecimento e 4 - Híbridos. Neste trabalho será explorada a técnica de Filtragem Colaborativa \textcolor{red}{com predição baseada em usuário}, introduzida por \cite{resnick1994grouplens}, que recomendam itens baseados na utilização desses pela comunidade de usuários.

% Os algoritmos de Filtragem Colaborativa podem ser divididos em dois grandes grupos de técnicas: baseados em memória e baseados em modelo. Os algoritmos baseados em memória, também conhecidos como Baseados em Vizinhança, possuem grande destaque pelo pioneirismo \cite{goldberg1992using}. Para estes sistemas, o interesse do usuário \textit{u} no item \textit{i} é calculado usando as avaliações dos seus usuários mais próximos. Para isso, é necessário armazenar as avaliações de cada usuário e obter os \textit{K} usuários mais próximos de \textit{u}. Calcular essa proximidade de forma eficiente é fundamental para que se obtenha bons resultados. Na sessão seguinte são apresentadas as técnicas de cálculo de similaridade que foram estudadas neste trabalho.

\section{Metodologia}

O conjunto de dados que foram utilizados trata-se de um \textit{dataset} do \textit{MovieLens}, disponível em \url{http://grouplens.org/datasets/movielens}. Inicialmente, os dados foram embaralhados e após esse embaralhamento, dois conjuntos foram formados. O primeiro conjunto de dados, com 90\% da base, separado para treino e o segundo conjunto de dados, com 10\% da base para compor o conjunto de teste. 

O SVD regularizado (RSVD) \cite{funk2006netflix}, que foi a técnica implementada neste trabalho, possui diversos parâmetros. São eles: $\lambda$,  a taxa de regularização, $k$ a dimensão de características a serem utilizadas e, por fim, $lrate$ que é a taxa de aprendizagem. Para que fosse encontrado o conjunto de parâmetros que produzia o melhor resultado para este conjunto de dados, o modelo foi submetido a variações destes parâmetros. Para cada parâmetro $p$, fixou-se os demais nos melhores valores até então encontrados e variou-se $p$ para encontrar o valor que produzia o melhor resultado.

A seção seguinte apresenta os resultados dos experimentos realizados para cada variação dos parâmetros, permitindo assim, observar quais parâmetros se adequam melhor a esse cenário. Cabe ressaltar que encontrar o melhor conjunto de parâmetros é uma tarefa custosa, pois é realizada através de testes empíricos e esses testes podem ser demorados, tornando esse processo muito custoso e, dependendo do caso até inviável.


% Para a realização deste trabalho foi utilizado um conjunto de dados do \textit{MovieLens}, disponível em \textcolor{red}{Onde?}. Com a finalidade de obter resultados que representem melhor a realidade, os dados foram divididos utilizando técnicas de \textcolor{red}{ \textit{crossvalidation}?}. Os dados foram divididos em 80\% para treino e 20\% para teste.

% Uma vez que os dados foram devidamente separados, o conjunto de teste foi escondido enquanto o algoritmo utilizava o conjunto de treino para aprende as características e relações entre usuário e item. Posteriormente, o conjunto de treino foi utilizado para que fosse analisada a acurácia da técnica aplicada.

% Buscando obter o melhor de cada medida de similaridade, o algoritmo passou por diversos testes, variando seus parâmetros de forma que pudesse ser observado como o KNN se comporta com determinada medida de similaridade, tendo seus parâmetros variados. O principal parâmetro testado foi o número de vizinhos que foi considerado para a predição. Outros parâmetros como a tolerância de similaridade, da técnica apresentada na seção 2.5, também foram submetidos a testes.

% A seção seguinte apresenta de forma objetiva algumas características de cada um dos experimentos realizados para cada medida de similaridade, bem como os resultados alcançados com o experimento.

\section{Experimentos e Resultados}

Esta seção mostra os resultados obtidos com o RSVD, submetido às diversas variações de seus parâmetros. Para analisar a acurácia das técnicas de similaridade, foram utilizadas duas medidas comuns para avaliar o desempenho das recomendações. São elas: \textit{Mean Absolute Error} (MAE), dada pela equação \ref{mae} e \textit{Root Mean Squared Error} (RMSE), dada pela equação \ref{rmse}. O critério de parada utilizado em todos os testes, foi dado por uma taxa de melhora inferior a $0.0001$ no RMSE ou por um número máximo de iterações $i = 250$.

\begin{equation} \label{mae}
MAE(f) = \frac{\sum\limits_{r_{ui} \in R_{test}} |f(u,i) - r_{ui}|}{|R_{test}|}
\end{equation}

\begin{equation} \label{rmse}
RMSE(f) = \sqrt[]{\frac{\sum\limits_{r_{ui} \in R_{test}} (|f(u,i) - r_{ui}|)^2}{|R_{test}|}}
\end{equation}

A figura \ref{grafico:progress} apresenta o processo de melhora das predições do RSVD. A melhora pode ser observada com a minimização do MAE, no gráfico à esquerda ou do RMSE, no gráfico à direita. Através dos gráficos, é possível analisar que o erro, tanto do treino quanto do teste decresce rapidamente até que começa a se estabilizar. A melhora se dá através dos reajustes das matrizes de características latentes  $P$ e $Q$. Já a estabilização se dá quando o método não consegue mais reajustar essa matriz, de modo que melhore suas predições. É importante verificar que o erro do conjunto de teste se estabiliza de forma mais rápida enquanto o erro do conjunto de treino continua diminuindo. Isso mostra que de fato o modelo está buscando se adequar ao conjunto de dados utilizados para treinamento, mesmo que isso já não interfira tanto nos resultados das predições do conjunto de teste.

\begin{figure}[!ht]
\begin{center}
\subfigure {
\begin{tikzpicture}
\begin{axis}[scale only axis, height=5cm,
width=5cm, title=MAE, xlabel=Iterações, ylabel=Erro]
% [legend pos= north west]
\addplot+[mark=none] table [x=iteration, y=mae_train, col sep=comma] {results/test_progress.csv};
\addplot+[mark=none] table [x=iteration, y=mae_test, col sep=comma] {results/test_progress.csv};
\legend{Train,Test}
\end{axis}
\end{tikzpicture}
}
\subfigure {
\begin{tikzpicture}
\begin{axis}[scale only axis, height=5cm,
width=5cm, title=RMSE, xlabel=Iterações, ylabel=Erro]
% [legend pos= north west]
\addplot+[mark=none] table [x=iteration, y=rmse_train, col sep=comma] {results/test_progress.csv};
\addplot+[mark=none] table [x=iteration, y=rmse_test, col sep=comma] {results/test_progress.csv};
\legend{Train,Test}
\end{axis}
\end{tikzpicture}
}
\end{center}
\caption{Melhoria da predição. }
\label{grafico:progress}
\end{figure}

A figura \ref{grafico:lambda} mostra o gráfico que apresenta os erros MAE e RMSE do RSVD, variando-se o $\lambda$, que é a taxa de regularização responsável por ``controlar" as atualizações das matrizes de variáveis latentes. Para este teste, o parâmetro analisado iniciou-se com o valor $0.05$ e foi incrementado em $0.01$, para cada caso de teste, até atingir o valor máximo, que foi definido como sendo $0.15$. Através da análise do gráfico é possível inferir que a melhor configuração para o $\lambda$, fixando os demais parâmetros é $\lambda = 0.11$, chegando a apresentar um MAE = $0.727$ e RMSE = $0.915$.

\begin{figure}[!ht]
\begin{center}
\begin{tikzpicture}
\begin{axis}[legend pos=outer north east, title=, xlabel=Valores para $\lambda$, ylabel=Erro]
\addplot+[mark=none] table [x=lambda, y=rmse, col sep=comma] {results/test_lambda.csv};
\addplot+[mark=none] table [x=lambda, y=mae, col sep=comma] {results/test_lambda.csv};
\legend{RMSE,MAE}
\end{axis}
\end{tikzpicture}
\end{center}
\caption{Relação entre $\lambda$ e o erro da predição. }
\label{grafico:lambda}
\end{figure}

\pagebreak
A figura \ref{grafico:lrate} mostra também o gráfico do MAE e do RMSE, porém variando-se o $lrate$. Esse parâmetro controla a taxa de ``aprendizagem" do RSVD para cada iteração. Pôde-se observar que esse é um parâmetro essencial para o bom funcionamento do algoritmo, afinal, o gráfico em momento algum ficou estável. É possível observar que ao iniciar os testes com $lrate = 0.0001$ o modelo apresentava um resultado pouco satisfatório. Mas, incrementando o $lrate$ em passos de $0.0065$, observou-se uma rápida melhora nos resultados logo no primeiro incremento, apresentando MAE = $0.728$ e RMSE = $0.922$. A partir deste valor, o resultado piora quase que proporcionalmente ao incremento de $lrate$, portanto, para estes testes, o melhor valor para este parâmetro é $0.0066$.

\begin{figure}[!ht]
\begin{center}
\begin{tikzpicture}
\begin{axis}[legend pos=outer north east, title=, xlabel=Valores para $lrate$, ylabel=Erro]
% [legend pos= north west]
\addplot+[mark=none] table [x=lrate, y=rmse, col sep=comma] {results/test_lrate.csv};
\addplot+[mark=none] table [x=lrate, y=mae, col sep=comma] {results/test_lrate.csv};
\legend{RMSE,MAE}
\end{axis}
\end{tikzpicture}
\end{center}
\caption{Relação entre $lrate$ e o erro da predição.}
\label{grafico:lrate}
\end{figure}

Por fim, a figura \ref{grafico:k} apresenta o gráfico do MAE e RMSE, variando-se o $k$. Esse parâmetro representa a dimensão de características, ou variáveis latentes que serão consideradas na predição. Os resultados mostram que a partir de um determinado valor, a variação de $k$ não apresenta grandes variações no resultado. Pode-se observar que aumentar $k$ indefinidamente, apesar de considerar mais características para a predição, não necessariamente irá melhorar os resultados, inclusive essa alteração implicou em uma pequena piora, para esse cenário. Neste caso de teste, o parâmetro $k$ iniciou-se com o valor $1$ e foi até $100$, em intervalos unitários. Os melhores resultados obtidos foram com $k = 10$, alcançando MAE = $0.724$ e RMSE = $0.918$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \textcolor{red}{Considerar refazer os testes iniciando de 1 até 40, com passos mais curtos.}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[!ht]
\begin{center}
\begin{tikzpicture}
\begin{axis}[legend pos=outer north east, title=, xlabel=Valores para $k$, ylabel=Erro]
% [legend pos= north west]
\addplot+[mark=none] table [x=k, y=rmse, col sep=comma] {results/test_k.csv};
\addplot+[mark=none] table [x=k, y=mae, col sep=comma] {results/test_k.csv};
\legend{RMSE,MAE}
\end{axis}
\end{tikzpicture}
\end{center}
\caption{Relação entre $k$ e o erro da predição. }
\label{grafico:k}
\end{figure}

\section{Conclusão}

Este trabalho teve como principal finalidade realizar uma análise do impacto dos parâmetros sobre as predições do algoritmo RSVD, método utilizado em sistemas de recomendação por filtragem colaborativa baseado em modelo. Utilizar o método baseado em modelo apresenta algumas vantagens se comparado aos métodos baseados em memória, uma delas é a simplicidade dos algoritmos baseados em modelo e seu melhor desempenho, na média. Outra vantagem é a escalabilidade fornecida por essa técnica, resolvendo de forma mais adequada o problema da inserção de um novo usuário ou item.

Analisando os resultados obtidos com a variação dos parâmetros do RSVD, conclui-se que um bom ajuste para os parâmetros para este cenário é $\lambda = 0.11$, $k = 10$ e $lrate = 0.0066$, chegando a obter RMSE = $0.9178$ e MAE = $0.7262$. Durante os testes, foi percebido também a sensibilidade que o RSVD possui. Pequenas alterações na configuração dos seus parâmetros podem acarretar em mudanças consideráveis no resultado. Outro fator observado é que muitas vezes o resultado final pode ser parecido, no entanto, a velocidade de convergência é diferente. Esse fator pode ser relevante quando o tempo é um fator limitante, se fazendo necessário estudar até que ponto vale a pena esperar várias iterações por uma melhora baixa.

Por fim, conclui-se que identificar os melhores parâmetros para o cenário do problema é fundamental, afinal, esses parâmetros mudam de acordo com as características do problema. Esse passo é essencial para que se obtenha resultados satisfatórios, pois como foi mostrado, os resultados das predições estão intimamente relacionados aos parâmetros do RSVD.

% O objetivo principal deste trabalho foi propor uma análise da qualidade da predição de recomendações utilizando o algoritmo KNN, que é uma amplamente utilizado nos sistemas de recomendação com filtragem colaborativa. Foram apresentadas quatro técnicas de similaridade já conhecidas da literatura e foi proposta uma nova medida de similaridade, que se mostrou bastante eficiente.

% Pode-se observar que o ajuste dos parâmetros do algoritmo é fundamental para que ele apresente bons resultados. O principal parâmetro deste algoritmo é o número de vizinhos $k$ a ser considerado. Encontrar o $k$ ótimo não é uma tarefa trivial e requer muitos testes empíricos. Testes estes que demoram para ser computados, dada a grande quantidade de dados e complexidade do algoritmo.

% Por fim, conclui-se que encontrar uma boa medida de similaridade e realizar os ajustes corretos dos parâmetros é fundamental para que o sistema alcance bons resultados. Saber ponderar entre maior cobertura e melhor predição é fundamental, afinal, aumentar um implica em diminuir o outro. 

% \begin{figure}[ht]
% \centering
% \includegraphics[width=1.2\textwidth]{figura_1.png}
% \caption{Proporção de domicílios com acesso a Internet  por área}
% \label{fig:figura}
% \end{figure}

% \/*
% ISSO AQUI EH UM COMENTÁRIO
% de boa!
% */

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}